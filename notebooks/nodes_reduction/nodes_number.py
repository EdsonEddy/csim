"""
The files prev_nodes_number.txt and post_nodes_number.txt were generated by running
this script on the same dataset (large_dataset) used in the experiments.

* For prev_nodes_number.txt, we applied Normalize and PruneAndHash with different configurations,
removed token and rule exclusions, disabled rule collapsing, and kept all nodes generated by ANTLR.
(Changes in the file /csim/csim/python/utils.py)

* For post_nodes_number.txt, we did not modify the rule/exclusion or collapsing configurations.
"""


from pathlib import Path
import sys
from csim import ANTLR_parse, Normalize, PruneAndHash
from csim.utils import read_file

path = sys.argv[1] if len(sys.argv) > 1 else str(Path(__file__).parent / "../large_dataset")
dir = Path(path)

if not dir.is_dir():
    raise ValueError(f"Error: {path}")

lang = "python"
results = []
for p in dir.iterdir():
    if p.is_file() and ".py" in str(p):
        try:
            file_name, content = read_file(str(p))
            if content is None:
                # Error already printed in read_file; skip this file
                continue
            T = ANTLR_parse(file_name, content, lang)
            N1 = Normalize(T, lang)
            P1, len_P1 = PruneAndHash(N1, lang)
            results.append(len_P1)
        except Exception as e:
            print(f"Error {p.name}: {e}")
            continue

print(results)
